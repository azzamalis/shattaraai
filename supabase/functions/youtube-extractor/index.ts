import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.50.0';
import { fetchWithRetry, logRetryMetrics } from '../_shared/retryUtils.ts';
import { normalizeTranscript } from '../_shared/transcriptNormalization.ts';
import { 
  extractYouTubeTranscript, 
  extractChapterTranscripts as extractChapterTranscriptsFromSegments,
  TranscriptSegment 
} from '../_shared/youtubeTranscript.ts';
import {
  parseChaptersFromDescription,
  validateChapters,
  analyzeChapterCoverage,
  Chapter
} from '../_shared/chapterParsing.ts';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface YouTubeExtractorRequest {
  url: string;
  contentId: string;
}

interface YouTubeData {
  title: string;
  description: string;
  duration: number;
  transcript: string;
  transcriptSegments: TranscriptSegment[];
  chapters: Array<{
    id?: string;
    title: string;
    startTime: number;
    endTime?: number;
    transcript?: string;
    source?: string;
  }>;
  chapterMetadata: {
    source: string;
    parseMethod: string;
    originalCount: number;
    cleanedCount: number;
    coverage: number;
    hadDuplicates: boolean;
    hadOverlaps: boolean;
  };
  metadata: {
    videoId: string;
    publishedAt: string;
    channelTitle: string;
    viewCount: string;
    thumbnails: any;
    hasRealTranscript: boolean;
    transcriptSource: string;
    transcriptLanguage: string;
    isAutoGenerated: boolean;
  };
}

function extractVideoId(url: string): string | null {
  const patterns = [
    /(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)/,
    /youtube\.com\/v\/([^&\n?#]+)/
  ];
  
  for (const pattern of patterns) {
    const match = url.match(pattern);
    if (match) return match[1];
  }
  return null;
}

function parseDuration(duration: string): number {
  const match = duration.match(/PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?/);
  if (!match) return 0;
  
  const hours = parseInt(match[1]) || 0;
  const minutes = parseInt(match[2]) || 0;
  const seconds = parseInt(match[3]) || 0;
  
  return hours * 3600 + minutes * 60 + seconds;
}

/**
 * Generate chapters from transcript using OpenAI
 */
async function generateChaptersFromTranscript(
  transcript: string,
  duration: number,
  openAIApiKey: string
): Promise<Array<{ id: string; title: string; startTime: number; endTime: number; summary: string }>> {
  const durationText = duration > 0 
    ? ` (Total duration: ${Math.floor(duration / 60)}:${String(Math.floor(duration % 60)).padStart(2, '0')})` 
    : '';
  
  // Truncate transcript if too long (keep first ~8000 chars for context)
  const maxTranscriptLength = 8000;
  const truncatedTranscript = transcript.length > maxTranscriptLength
    ? transcript.substring(0, maxTranscriptLength) + '... [truncated]'
    : transcript;
  
  console.log(`Generating chapters with AI for ${transcript.length} char transcript${durationText}`);
  
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${openAIApiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: `You are an expert content analyzer. Generate meaningful chapters for the provided YouTube transcript${durationText}. 
          Return a JSON array of chapters with this exact structure:
          [
            {
              "id": "chapter-1",
              "title": "Chapter Title",
              "startTime": 0,
              "endTime": 120,
              "summary": "Brief summary of this chapter content"
            }
          ]
          
          Guidelines:
          - Create 3-8 chapters depending on content length
          - Use descriptive titles that capture the main topic
          - Ensure chapters don't overlap and cover the entire video
          - Provide meaningful summaries (1-2 sentences)
          - IMPORTANT: All timestamps must be within the actual duration${duration ? ` (${duration} seconds max)` : ''}
          - Distribute chapters proportionally across the video duration
          - Return only the JSON array, no additional text`
        },
        {
          role: 'user',
          content: `Please analyze this transcript and create chapters${durationText}:\n\n${truncatedTranscript}`
        }
      ],
      max_tokens: 1000,
      temperature: 0.3 // Lower temperature for more consistent output
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
  }

  const result = await response.json();
  let responseText = result.choices[0].message.content;
  
  // Remove markdown code blocks if present
  if (responseText.includes('```json')) {
    responseText = responseText.replace(/```json\s*|\s*```/g, '').trim();
  } else if (responseText.includes('```')) {
    responseText = responseText.replace(/```\s*|\s*```/g, '').trim();
  }
  
  let chapters = JSON.parse(responseText);
  
  if (!Array.isArray(chapters)) {
    chapters = chapters.chapters || [];
  }
  
  // Validate and fix timestamps
  if (duration > 0) {
    chapters = chapters.map((chapter: any, index: number) => {
      const adjustedStartTime = Math.max(0, Math.min(chapter.startTime || 0, duration));
      const adjustedEndTime = Math.max(adjustedStartTime + 1, Math.min(chapter.endTime || duration, duration));
      
      return {
        id: chapter.id || `chapter-${index + 1}`,
        title: chapter.title || `Chapter ${index + 1}`,
        startTime: adjustedStartTime,
        endTime: adjustedEndTime,
        summary: chapter.summary || '',
        source: 'ai_generated'
      };
    });
  }
  
  return chapters;
}

async function getYouTubeData(videoId: string): Promise<YouTubeData> {
  const apiKey = Deno.env.get('YOUTUBE_API_KEY');
  const supadataApiKey = Deno.env.get('SUPADATA_API_KEY');
  
  if (!apiKey) {
    throw new Error('YouTube API key not configured');
  }

  // Fetch video metadata with retry logic
  const startTime = Date.now();
  const videoResponse = await fetchWithRetry(
    `https://www.googleapis.com/youtube/v3/videos?part=snippet,contentDetails,statistics&id=${videoId}&key=${apiKey}`,
    { method: 'GET' },
    {
      maxRetries: 3,
      timeoutMs: 30000,
      onRetry: (attempt, error) => {
        console.log(`YouTube API retry ${attempt}: ${error.message}`);
      }
    }
  );
  
  logRetryMetrics('youtube_api_video', 1, videoResponse.ok, Date.now() - startTime);
  
  if (!videoResponse.ok) {
    throw new Error(`YouTube API error: ${videoResponse.status}`);
  }
  
  const videoData = await videoResponse.json();
  
  if (!videoData.items || videoData.items.length === 0) {
    throw new Error('Video not found or not accessible');
  }
  
  const video = videoData.items[0];
  const duration = parseDuration(video.contentDetails.duration);
  
  // Use the new transcript extraction module with Supadata + fallback
  console.log('Extracting transcript with Supadata + timedtext fallback...');
  const transcriptResult = await extractYouTubeTranscript(videoId, {
    supadataApiKey: supadataApiKey || undefined,
    preferredLang: 'en',
    fallbackDescription: video.snippet.description
  });
  
  console.log(`Transcript extraction: source=${transcriptResult.source}, segments=${transcriptResult.segments.length}, chars=${transcriptResult.metadata.characterCount}`);
  
  // Parse chapters from description using improved parser
  console.log('Parsing chapters from description with improved parser...');
  const chapterParseResult = parseChaptersFromDescription(video.snippet.description);
  console.log(`Chapter parsing: found ${chapterParseResult.metadata.originalCount} raw, ${chapterParseResult.metadata.cleanedCount} cleaned, duplicates=${chapterParseResult.metadata.hadDuplicates}`);
  
  // Validate chapters against video duration
  let { chapters: validatedChapters, corrections } = validateChapters(
    chapterParseResult.chapters,
    duration
  );
  
  if (corrections.length > 0) {
    console.log('Chapter corrections applied:', corrections);
  }
  
  // If no chapters found in description and we have a transcript, generate chapters using AI
  let chapterSource = chapterParseResult.metadata.source;
  if (validatedChapters.length === 0 && transcriptResult.transcript.length > 100) {
    console.log('No chapters in description, generating from transcript using AI...');
    
    const openAIApiKey = Deno.env.get('OPENAI_API_KEY');
    if (openAIApiKey) {
      try {
        const aiChapters = await generateChaptersFromTranscript(
          transcriptResult.transcript,
          duration,
          openAIApiKey
        );
        
        if (aiChapters.length > 0) {
          validatedChapters = aiChapters;
          chapterSource = 'ai_generated';
          console.log(`AI generated ${aiChapters.length} chapters from transcript`);
        }
      } catch (aiError) {
        console.error('AI chapter generation failed:', aiError);
        // Continue without chapters rather than failing
      }
    } else {
      console.log('No OpenAI API key available for chapter generation');
    }
  }
  
  // Analyze chapter coverage
  const coverageAnalysis = analyzeChapterCoverage(validatedChapters, duration);
  console.log(`Chapter coverage: ${Math.round(coverageAnalysis.coverage * 100)}%, gaps: ${coverageAnalysis.gaps.length}`);
  
  // Extract chapter-specific transcripts from timestamped segments
  const chaptersWithTranscripts = transcriptResult.segments.length > 0
    ? extractChapterTranscriptsFromSegments(transcriptResult.segments, validatedChapters)
    : validatedChapters.map(ch => ({ ...ch, transcript: '' }));
  
  const hasRealTranscript = transcriptResult.source !== 'description' && 
                            transcriptResult.source !== 'none' &&
                            transcriptResult.transcript.length > 0;
  
  return {
    title: video.snippet.title,
    description: video.snippet.description,
    duration,
    transcript: transcriptResult.transcript,
    transcriptSegments: transcriptResult.segments,
    chapters: chaptersWithTranscripts,
  chapterMetadata: {
      source: chapterSource,
      parseMethod: chapterSource === 'ai_generated' ? 'openai_gpt4o_mini' : chapterParseResult.metadata.parseMethod,
      originalCount: chapterSource === 'ai_generated' ? validatedChapters.length : chapterParseResult.metadata.originalCount,
      cleanedCount: validatedChapters.length,
      coverage: coverageAnalysis.coverage,
      hadDuplicates: chapterParseResult.metadata.hadDuplicates,
      hadOverlaps: chapterParseResult.metadata.hadOverlaps
    },
    metadata: {
      videoId,
      publishedAt: video.snippet.publishedAt,
      channelTitle: video.snippet.channelTitle,
      viewCount: video.statistics.viewCount,
      thumbnails: video.snippet.thumbnails,
      hasRealTranscript,
      transcriptSource: transcriptResult.source,
      transcriptLanguage: transcriptResult.language,
      isAutoGenerated: transcriptResult.isAutoGenerated
    }
  };
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabaseUrl = Deno.env.get('SUPABASE_URL') ?? '';
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? '';
    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    // ========== IP-BASED RATE LIMITING ==========
    const clientIP = req.headers.get('x-forwarded-for')?.split(',')[0]?.trim() || 
                     req.headers.get('x-real-ip') || 
                     'unknown';
    
    console.log('YouTube extractor request from IP:', clientIP);

    const { data: rateCheck, error: rateError } = await supabase.rpc('check_ip_rate_limit', {
      p_ip_address: clientIP,
      p_endpoint: 'youtube-extractor',
      p_max_requests: 20,  // 20 requests per hour
      p_window_minutes: 60
    });

    if (rateError) {
      console.error('Rate limit check error:', rateError);
      // Continue anyway - don't block on rate limit errors
    } else if (rateCheck && rateCheck.length > 0 && !rateCheck[0].allowed) {
      console.log('Rate limit exceeded for IP:', clientIP);
      return new Response(
        JSON.stringify({ 
          success: false,
          error: 'Rate limit exceeded. Please try again later.',
          reset_time: rateCheck[0].reset_time
        }),
        { 
          status: 429, 
          headers: { 
            ...corsHeaders, 
            'Content-Type': 'application/json',
            'Retry-After': '3600'
          } 
        }
      );
    }

    const { url, contentId }: YouTubeExtractorRequest = await req.json();
    
    console.log('Extracting YouTube data for:', url);
    
    const videoId = extractVideoId(url);
    if (!videoId) {
      throw new Error('Invalid YouTube URL');
    }

    // Update progress: Extracting with granular status tracking
    await supabase
      .from('content')
      .update({
        processing_status: 'processing',
        transcript_status: 'processing',
        chapters_status: 'pending',
        last_transcript_attempt: new Date().toISOString(),
        transcript_error: null, // Clear previous error
        chapters_error: null,
        metadata: {
          currentStep: 'extracting',
          progress: 25
        }
      })
      .eq('id', contentId);
    
    const youtubeData = await getYouTubeData(videoId);
    
    // Update progress: Analyzing
    await supabase
      .from('content')
      .update({
        metadata: {
          currentStep: 'analyzing',
          progress: 60
        }
      })
      .eq('id', contentId);
    
    // Store YouTube URL in the youtube-content bucket
    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('youtube-content')
      .upload(`${contentId}/metadata.json`, JSON.stringify({
        url,
        videoId,
        extractedAt: new Date().toISOString(),
        transcriptSource: youtubeData.metadata.transcriptSource,
        segmentCount: youtubeData.transcriptSegments.length,
        chapterMetadata: youtubeData.chapterMetadata
      }), {
        contentType: 'application/json',
        upsert: true
      });

    const storagePath = uploadData?.path || url;

    // Normalize transcript for cleaner AI processing
    const normalizedResult = normalizeTranscript(youtubeData.transcript);
    console.log(`YouTube transcript normalization: removed ${normalizedResult.fillerCount} fillers, fixed ${normalizedResult.repetitionCount} repetitions, ${normalizedResult.cleanupPercentage}% cleaned`);

    // Determine chapter status based on extraction results
    const chaptersStatus = youtubeData.chapters.length > 0 ? 'completed' : 'not_applicable';

    // Update content with extracted data and storage path
    const { error: contentError } = await supabase
      .from('content')
      .update({
        title: youtubeData.title,
        filename: youtubeData.title,
        storage_path: storagePath,
        text_content: normalizedResult.cleaned, // Use normalized for AI features
        chapters: youtubeData.chapters,
        processing_status: 'completed',
        transcript_status: youtubeData.metadata.hasRealTranscript ? 'completed' : 'failed',
        chapters_status: chaptersStatus,
        transcript_error: youtubeData.metadata.hasRealTranscript ? null : 'No transcript available, using description as fallback',
        last_chapters_attempt: youtubeData.chapters.length > 0 ? new Date().toISOString() : null,
        metadata: {
          ...youtubeData.metadata,
          chapters: youtubeData.chapters,
          chapterMetadata: youtubeData.chapterMetadata,
          extractedAt: new Date().toISOString(),
          hasTranscript: youtubeData.transcript.length > 0,
          hasChapters: youtubeData.chapters.length > 0,
          chapterCount: youtubeData.chapters.length,
          chapterCoverage: youtubeData.chapterMetadata.coverage,
          hasRealTranscript: youtubeData.metadata.hasRealTranscript,
          transcriptSource: youtubeData.metadata.transcriptSource,
          transcriptLanguage: youtubeData.metadata.transcriptLanguage,
          isAutoGenerated: youtubeData.metadata.isAutoGenerated,
          segmentCount: youtubeData.transcriptSegments.length,
          currentStep: 'completed',
          progress: 100,
          hasNormalizedTranscript: true,
          normalization: {
            fillerCount: normalizedResult.fillerCount,
            repetitionCount: normalizedResult.repetitionCount,
            cleanupPercentage: normalizedResult.cleanupPercentage,
            originalLength: normalizedResult.metadata.originalLength,
            cleanedLength: normalizedResult.metadata.cleanedLength
          }
        }
      })
      .eq('id', contentId);
    
    if (contentError) {
      console.error('Error updating content:', contentError);
      throw new Error('Failed to update content');
    }
    
    // Create or update recording entry with raw transcript and segments
    const { error: recordingError } = await supabase
      .from('recordings')
      .upsert({
        content_id: contentId,
        duration: youtubeData.duration,
        transcript: youtubeData.transcript, // Store raw for reference
        chapters: youtubeData.chapters,
        real_time_transcript: youtubeData.transcriptSegments, // Store timestamped segments
        processing_status: 'completed'
      });
    
    if (recordingError) {
      console.error('Error creating recording:', recordingError);
    }
    
    console.log(`YouTube extraction completed: ${youtubeData.title} (source: ${youtubeData.metadata.transcriptSource})`);
    
    return new Response(JSON.stringify({
      success: true,
      data: {
        ...youtubeData,
        // Don't include full segments in response to reduce payload
        transcriptSegments: undefined,
        segmentCount: youtubeData.transcriptSegments.length
      }
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
    
  } catch (error) {
    console.error('YouTube extraction error:', error);
    
    // Update content with failed status and error details
    try {
      const supabaseUrl = Deno.env.get('SUPABASE_URL') ?? '';
      const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? '';
      const supabase = createClient(supabaseUrl, supabaseServiceKey);
      const { contentId } = await req.clone().json().catch(() => ({}));
      
      if (contentId) {
        await supabase
          .from('content')
          .update({
            processing_status: 'failed',
            transcript_status: 'failed',
            transcript_error: error.message || 'Unknown extraction error'
          })
          .eq('id', contentId);
      }
    } catch (updateError) {
      console.error('Failed to update content status:', updateError);
    }
    
    return new Response(JSON.stringify({
      success: false,
      error: error.message
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});
